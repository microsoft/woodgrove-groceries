using Microsoft.AspNetCore.SignalR;
using OpenAI.Assistants;
using OpenAI.Chat;

namespace woodgrovedemo.Helpers.AzureAI;

// This class is an endpoint for the SignalR hub that handles chat messages.
// The edpoint is protected by the "ExclusiveDemosOnly" authorization policy (defined in Startup.cs).
// It means that only users who are members of the exclusive demos security group can access this endpoint
public class ChatHub1 : Hub
{
    private readonly OpenAI.OpenAIClient _openAIClient;
    private readonly IConfiguration _configuration;

    public ChatHub1(IConfiguration configuration, OpenAI.OpenAIClient openAIClient)
    {
        _openAIClient = openAIClient;
        _configuration = configuration;
    }

    public async Task SendMessage(string user, string prompt)
    {
        try
        {
            AssistantClient assistantClient = _openAIClient.GetAssistantClient();

            AssistantCreationOptions options = new AssistantCreationOptions
            {
                Name = "Woodgrove Assistant",
                Instructions = "You are an AI assistant that helps people find information."
            };

            // Create the assistant that manages conversation threads, and utilizes configured tools.
            Assistant assistant = await assistantClient.CreateAssistantAsync(_configuration.GetSection("Demos:AzureOpenAI:DeploymentName").Value!, options);

            // Configure and create the conversation thread
            ThreadCreationOptions threadOptions = new()
            {
                InitialMessages = { prompt }
            };

            // Fist, we inform the client that we are starting to process the message
            await Clients.All.SendAsync("ReceiveStartTyping", user, "Processing your message...");

            // Create a thread that stores messages and automatically handle truncation to fit content into a model's context.
            ThreadRun threadRun = assistantClient.CreateThreadAndRun(assistant.Id, threadOptions);

            // Sent the prompt and monitor progress until the thread run is complete
            do
            {
                Thread.Sleep(TimeSpan.FromSeconds(1));
                threadRun = assistantClient.GetRun(threadRun.ThreadId, threadRun.Id);
            }
            while (!threadRun.Status.IsTerminal);

            // Get the messages from the thread run
            var messages = assistantClient.GetMessagesAsync(
                threadRun.ThreadId,
                new MessageCollectionOptions()
                {
                    Order = MessageCollectionOrder.Ascending
                });


            await foreach (ThreadMessage message in messages)
            {
                // Print out the messages from the assistant
                foreach (MessageContent contentItem in message.Content)
                {
                    if (message.Role.ToString().ToUpper() != "USER" && !string.IsNullOrEmpty(contentItem.Text))
                    {
                        await Clients.All.SendAsync("ReceivePartialResponse", user, contentItem.Text);

                        // if (contentItem.TextAnnotations.Count > 0)
                        // {
                        //     Console.WriteLine();
                        // }

                        // Include annotations, if any
                        // foreach (TextAnnotation annotation in contentItem.TextAnnotations)
                        // {
                        //     if (!string.IsNullOrEmpty(annotation.InputFileId))
                        //     {
                        //         Console.WriteLine($"* File citation, file ID: {annotation.InputFileId}");
                        //     }
                        //     if (!string.IsNullOrEmpty(annotation.OutputFileId))
                        //     {
                        //         Console.WriteLine($"* File output, new file ID: {annotation.OutputFileId}");
                        //     }
                        // }
                    }
                }
                Console.WriteLine();
            }

            await Clients.All.SendAsync("ReceiveEndTyping", user, "Done processing your message.");
        }
        catch (Exception ex)
        {
            await Clients.All.SendAsync("ReceiveMessage", "System", $"Error: {ex.Message}");
        }
    }

    /*public async Task SendMessage(string user, string message)
    {
        ChatClient chatClient = _openAIClient.GetChatClient(_configuration.GetSection("Demos:AzureOpenAI:DeploymentName").Value!);

        // Create a chat comoletion options object
        ChatCompletionOptions options = new ChatCompletionOptions();
        options.MaxOutputTokenCount = 1000; // Set the maximum number of tokens in the response
        options.Temperature = 0.7f; // Set the temperature for randomness in the response
        options.TopP = 0.95f; // Set the top-p sampling parameter 

        // Create a list of chat messages
        // The first message is a system message that sets the context for the assistant
        List<ChatMessage> messages = new List<ChatMessage>()
        {
            new SystemChatMessage("You are an AI assistant that helps people find information."),
            new UserChatMessage(message),
        };

        try
        {
            // Start streaming the chat completion
            // This allows the assistant to send partial responses as they are generated by Azure OpenAI.
            // The client can then display the partial responses to the user in real-time.

            // Fist, we inform the client that we are starting to process the message
            await Clients.All.SendAsync("ReceiveStartTyping", user, "Processing your message...");

            // Create a streaming chat completion that will handle the streaming of the chat completion.
            // The CompleteChatStreamingAsync method returns an async collection of StreamingChatCompletionUpdate objects.
            // Each StreamingChatCompletionUpdate object contains a ContentUpdate property that holds the partial response.
            System.ClientModel.AsyncCollectionResult<StreamingChatCompletionUpdate> completionUpdates = chatClient.CompleteChatStreamingAsync(messages, options);

            // The await foreach loop iterates over the streaming updates.
            await foreach (StreamingChatCompletionUpdate completionUpdate in completionUpdates)
            {
                // Iterate over the content parts in the completion update and send each part to the connected clients.
                // This foreach loop runs only once for each part of the response. Therefore, it can be done using [index]
                foreach (ChatMessageContentPart contentPart in completionUpdate.ContentUpdate)
                {
                    Console.Write(contentPart.Text);
                    await Clients.All.SendAsync("ReceivePartialResponse", user, contentPart.Text);
                }
            }

            // After the streaming is complete, we inform the client that we are done processing the message.
            await Clients.All.SendAsync("ReceiveEndTyping", user, "Done processing your message.");
        }
        catch (Exception ex)
        {
            // Log the error and send an error message back to the client (using the user ID)
            await Clients.All.SendAsync("ReceiveMessage", user, $"Error processing message: {ex.Message}");
        }
    }*/
}
