using Microsoft.AspNetCore.SignalR;
using OpenAI.Chat;

namespace woodgrovedemo.Helpers.AzureAI;

// This class is an endpoint for the SignalR hub that handles chat messages.
// The edpoint is protected by the "ExclusiveDemosOnly" authorization policy (defined in Startup.cs).
// It means that only users who are members of the exclusive demos security group can access this endpoint
public class ChatHub : Hub
{
    private readonly OpenAI.OpenAIClient _openAIClient;
    private readonly IConfiguration _configuration;

    public ChatHub(IConfiguration configuration, OpenAI.OpenAIClient openAIClient)
    {
        _openAIClient = openAIClient;
        _configuration = configuration;
    }

    public async Task SendMessage(string user, string message)
    {
        var chatClient = _openAIClient.GetChatClient(_configuration.GetSection("Demos:AzureOpenAI:DeploymentName").Value!);

        // Create a chat comoletion options object
        ChatCompletionOptions options = new ChatCompletionOptions();
        options.MaxOutputTokenCount = 1000; // Set the maximum number of tokens in the response
        options.Temperature = 0.7f; // Set the temperature for randomness in the response
        options.TopP = 0.95f; // Set the top-p sampling parameter 

        // Create a list of chat messages
        // The first message is a system message that sets the context for the assistant
        List<ChatMessage> messages = new List<ChatMessage>()
        {
            new SystemChatMessage("You are an AI assistant that helps people find information."),
            new UserChatMessage(message),
        };

        try
        {
            // The next few lines are commented out because they are not used in the streaming version.
            // This option sends the entire response at once after it is generated.
            /*ChatCompletion chatCompletion = await chatClient.CompleteChatAsync(messages, options);

            // Get the assistant's response
            string response = chatCompletion.Content[0].Text;

            // Send the response back to the connected clients (using the user ID)
            await Clients.All.SendAsync("ReceiveMessage", user, response);*/

            // Start streaming the chat completion
            // This allows the assistant to send partial responses as they are generated by Azure OpenAI.
            // The client can then display the partial responses to the user in real-time.

            // Fist, we inform the client that we are starting to process the message
            await Clients.All.SendAsync("ReceiveStartTyping", user, "Processing your message...");

            // Create a streaming chat completion that will handle the streaming of the chat completion.
            // The CompleteChatStreamingAsync method returns an async collection of StreamingChatCompletionUpdate objects.
            // Each StreamingChatCompletionUpdate object contains a ContentUpdate property that holds the partial response.
            System.ClientModel.AsyncCollectionResult<StreamingChatCompletionUpdate> completionUpdates = chatClient.CompleteChatStreamingAsync(messages, options);

            // The await foreach loop iterates over the streaming updates.
            await foreach (StreamingChatCompletionUpdate completionUpdate in completionUpdates)
            {
                // Iterate over the content parts in the completion update and send each part to the connected clients.
                // This foreach loop runs only once for each part of the response. Therefore, it can be done using [index]
                foreach (ChatMessageContentPart contentPart in completionUpdate.ContentUpdate)
                {
                    Console.Write(contentPart.Text);
                    await Clients.All.SendAsync("ReceivePartialResponse", user, contentPart.Text);
                }
            }

            // After the streaming is complete, we inform the client that we are done processing the message.
            await Clients.All.SendAsync("ReceiveEndTyping", user, "Done processing your message.");
        }
        catch (Exception ex)
        {
            // Log the error and send an error message back to the client (using the user ID)
            await Clients.All.SendAsync("ReceiveMessage", user, $"Error processing message: {ex.Message}");
        }
    }
}